{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns; sns.set(context = 'paper', style = 'whitegrid')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fabiannemazi\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fabiannemazi/Fag_nmbu/Dat200/CA3/Data\n"
     ]
    }
   ],
   "source": [
    "cd Fag_nmbu/Dat200/CA3/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_sample = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.202026</td>\n",
       "      <td>0.804586</td>\n",
       "      <td>0.401941</td>\n",
       "      <td>156.750985</td>\n",
       "      <td>166.643360</td>\n",
       "      <td>196.047271</td>\n",
       "      <td>168.302195</td>\n",
       "      <td>238.272512</td>\n",
       "      <td>230.066717</td>\n",
       "      <td>219.825159</td>\n",
       "      <td>...</td>\n",
       "      <td>530.048818</td>\n",
       "      <td>0.224254</td>\n",
       "      <td>297.630979</td>\n",
       "      <td>0.221186</td>\n",
       "      <td>0.331006</td>\n",
       "      <td>0.030905</td>\n",
       "      <td>5.881964</td>\n",
       "      <td>4.886747</td>\n",
       "      <td>2.899268</td>\n",
       "      <td>0.914463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.493933</td>\n",
       "      <td>0.396547</td>\n",
       "      <td>0.490325</td>\n",
       "      <td>79.868466</td>\n",
       "      <td>74.588417</td>\n",
       "      <td>107.521931</td>\n",
       "      <td>77.616408</td>\n",
       "      <td>207.299347</td>\n",
       "      <td>207.017288</td>\n",
       "      <td>198.373088</td>\n",
       "      <td>...</td>\n",
       "      <td>1927.718921</td>\n",
       "      <td>0.417120</td>\n",
       "      <td>699.293958</td>\n",
       "      <td>0.376378</td>\n",
       "      <td>0.451033</td>\n",
       "      <td>0.027579</td>\n",
       "      <td>1.536845</td>\n",
       "      <td>2.878474</td>\n",
       "      <td>1.860700</td>\n",
       "      <td>0.776574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.325500</td>\n",
       "      <td>-1.206000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>111.037400</td>\n",
       "      <td>105.016925</td>\n",
       "      <td>88.459000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.124575</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>173.704850</td>\n",
       "      <td>167.636150</td>\n",
       "      <td>150.273100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147800</td>\n",
       "      <td>0.220600</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>289.366625</td>\n",
       "      <td>281.537275</td>\n",
       "      <td>284.385325</td>\n",
       "      <td>...</td>\n",
       "      <td>223.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.354800</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>1036.000000</td>\n",
       "      <td>1628.000000</td>\n",
       "      <td>977.000000</td>\n",
       "      <td>1924.134700</td>\n",
       "      <td>1924.134700</td>\n",
       "      <td>1070.361600</td>\n",
       "      <td>...</td>\n",
       "      <td>35448.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11140.000000</td>\n",
       "      <td>4.491700</td>\n",
       "      <td>4.491700</td>\n",
       "      <td>0.362300</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                f1           f2           f3           f4           f5  \\\n",
       "count  7108.000000  7108.000000  7108.000000  7108.000000  7108.000000   \n",
       "mean      1.202026     0.804586     0.401941   156.750985   166.643360   \n",
       "std       0.493933     0.396547     0.490325    79.868466    74.588417   \n",
       "min       1.000000     0.000000     0.000000     0.000000    20.000000   \n",
       "25%       1.000000     1.000000     0.000000    99.000000   119.000000   \n",
       "50%       1.000000     1.000000     0.000000   139.000000   159.000000   \n",
       "75%       1.000000     1.000000     1.000000   199.000000   199.000000   \n",
       "max       8.000000     1.000000     1.000000   700.000000  1036.000000   \n",
       "\n",
       "                f6           f7           f8           f9          f10  ...  \\\n",
       "count  7108.000000  7108.000000  7108.000000  7108.000000  7108.000000  ...   \n",
       "mean    196.047271   168.302195   238.272512   230.066717   219.825159  ...   \n",
       "std     107.521931    77.616408   207.299347   207.017288   198.373088  ...   \n",
       "min      20.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%     119.000000   119.000000   111.037400   105.016925    88.459000  ...   \n",
       "50%     179.000000   159.000000   173.704850   167.636150   150.273100  ...   \n",
       "75%     239.000000   199.000000   289.366625   281.537275   284.385325  ...   \n",
       "max    1628.000000   977.000000  1924.134700  1924.134700  1070.361600  ...   \n",
       "\n",
       "                f16          f17           f18          f19          f20  \\\n",
       "count   7108.000000  7108.000000   7108.000000  7108.000000  7108.000000   \n",
       "mean     530.048818     0.224254    297.630979     0.221186     0.331006   \n",
       "std     1927.718921     0.417120    699.293958     0.376378     0.451033   \n",
       "min        0.000000     0.000000      0.000000    -4.325500    -1.206000   \n",
       "25%        0.000000     0.000000      0.000000     0.073800     0.124575   \n",
       "50%        0.000000     0.000000      0.000000     0.147800     0.220600   \n",
       "75%      223.750000     0.000000    298.000000     0.259100     0.354800   \n",
       "max    35448.000000     1.000000  11140.000000     4.491700     4.491700   \n",
       "\n",
       "               f21          f22          f23          f24        label  \n",
       "count  7108.000000  7108.000000  7108.000000  7108.000000  7108.000000  \n",
       "mean      0.030905     5.881964     4.886747     2.899268     0.914463  \n",
       "std       0.027579     1.536845     2.878474     1.860700     0.776574  \n",
       "min       0.000500     2.000000     1.000000     1.000000     0.000000  \n",
       "25%       0.015300     5.000000     2.000000     1.000000     0.000000  \n",
       "50%       0.023400     6.000000     4.000000     2.000000     1.000000  \n",
       "75%       0.036900     7.000000     7.000000     4.000000     2.000000  \n",
       "max       0.362300    10.000000    10.000000    10.000000     2.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop('ID', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "      <td>3828.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.196708</td>\n",
       "      <td>0.807471</td>\n",
       "      <td>0.403344</td>\n",
       "      <td>155.586207</td>\n",
       "      <td>167.296499</td>\n",
       "      <td>195.494775</td>\n",
       "      <td>167.078631</td>\n",
       "      <td>237.236440</td>\n",
       "      <td>231.573643</td>\n",
       "      <td>218.308170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388192</td>\n",
       "      <td>533.122780</td>\n",
       "      <td>0.209770</td>\n",
       "      <td>305.476489</td>\n",
       "      <td>0.213214</td>\n",
       "      <td>0.327013</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>5.934692</td>\n",
       "      <td>4.894723</td>\n",
       "      <td>2.970219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.494252</td>\n",
       "      <td>0.394337</td>\n",
       "      <td>0.490633</td>\n",
       "      <td>77.526193</td>\n",
       "      <td>75.221659</td>\n",
       "      <td>107.158278</td>\n",
       "      <td>77.998455</td>\n",
       "      <td>208.072372</td>\n",
       "      <td>202.544861</td>\n",
       "      <td>198.365134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685652</td>\n",
       "      <td>1951.117906</td>\n",
       "      <td>0.407198</td>\n",
       "      <td>765.739980</td>\n",
       "      <td>0.361149</td>\n",
       "      <td>0.463246</td>\n",
       "      <td>0.025133</td>\n",
       "      <td>1.554487</td>\n",
       "      <td>2.892309</td>\n",
       "      <td>1.909680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.226000</td>\n",
       "      <td>-4.013600</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>109.369475</td>\n",
       "      <td>109.594450</td>\n",
       "      <td>85.860275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>171.556450</td>\n",
       "      <td>171.053000</td>\n",
       "      <td>147.088400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>288.174200</td>\n",
       "      <td>283.120925</td>\n",
       "      <td>281.415400</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>0.246150</td>\n",
       "      <td>0.351200</td>\n",
       "      <td>0.036225</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>656.000000</td>\n",
       "      <td>1036.000000</td>\n",
       "      <td>1628.000000</td>\n",
       "      <td>1133.000000</td>\n",
       "      <td>1686.440400</td>\n",
       "      <td>1686.440400</td>\n",
       "      <td>1046.247600</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>35448.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11140.000000</td>\n",
       "      <td>4.491700</td>\n",
       "      <td>4.491700</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                f1           f2           f3           f4           f5  \\\n",
       "count  3828.000000  3828.000000  3828.000000  3828.000000  3828.000000   \n",
       "mean      1.196708     0.807471     0.403344   155.586207   167.296499   \n",
       "std       0.494252     0.394337     0.490633    77.526193    75.221659   \n",
       "min       1.000000     0.000000     0.000000     0.000000    20.000000   \n",
       "25%       1.000000     1.000000     0.000000    99.000000   119.000000   \n",
       "50%       1.000000     1.000000     0.000000   139.000000   159.000000   \n",
       "75%       1.000000     1.000000     1.000000   199.000000   199.000000   \n",
       "max       8.000000     1.000000     1.000000   656.000000  1036.000000   \n",
       "\n",
       "                f6           f7           f8           f9          f10  ...  \\\n",
       "count  3828.000000  3828.000000  3828.000000  3828.000000  3828.000000  ...   \n",
       "mean    195.494775   167.078631   237.236440   231.573643   218.308170  ...   \n",
       "std     107.158278    77.998455   208.072372   202.544861   198.365134  ...   \n",
       "min      20.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%     120.000000   119.000000   109.369475   109.594450    85.860275  ...   \n",
       "50%     179.000000   159.000000   171.556450   171.053000   147.088400  ...   \n",
       "75%     239.000000   199.000000   288.174200   283.120925   281.415400  ...   \n",
       "max    1628.000000  1133.000000  1686.440400  1686.440400  1046.247600  ...   \n",
       "\n",
       "               f15           f16          f17           f18          f19  \\\n",
       "count  3828.000000   3828.000000  3828.000000   3828.000000  3828.000000   \n",
       "mean      0.388192    533.122780     0.209770    305.476489     0.213214   \n",
       "std       0.685652   1951.117906     0.407198    765.739980     0.361149   \n",
       "min       0.000000      0.000000     0.000000      0.000000    -1.226000   \n",
       "25%       0.000000      0.000000     0.000000      0.000000     0.065200   \n",
       "50%       0.000000      0.000000     0.000000      0.000000     0.139600   \n",
       "75%       1.000000    219.000000     0.000000    297.000000     0.246150   \n",
       "max       5.000000  35448.000000     1.000000  11140.000000     4.491700   \n",
       "\n",
       "               f20          f21          f22          f23          f24  \n",
       "count  3828.000000  3828.000000  3828.000000  3828.000000  3828.000000  \n",
       "mean      0.327013     0.030220     5.934692     4.894723     2.970219  \n",
       "std       0.463246     0.025133     1.554487     2.892309     1.909680  \n",
       "min      -4.013600     0.000500     2.000000     1.000000     1.000000  \n",
       "25%       0.122000     0.015200     5.000000     2.000000     1.000000  \n",
       "50%       0.212600     0.023300     6.000000     4.000000     3.000000  \n",
       "75%       0.351200     0.036225     7.000000     7.000000     4.000000  \n",
       "max       4.491700     0.345400    10.000000    10.000000    10.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping significant outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating X and y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop('ID', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('label',1).values\n",
    "y = df_train['label'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc = make_pipeline(StandardScaler(), SVC(random_state=1))\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [{'svc__C': param_range,\n",
    "              'svc__kernel': ['linear']},\n",
    "             {'svc__gamma' : param_range,\n",
    "             'svc__kernel' : ['rbf']}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator = pipe_svc,\n",
    "                 param_grid = param_grid,\n",
    "                 scoring = 'accuracy',\n",
    "                 cv= 10,\n",
    "                 n_jobs= -1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.6830635118306351\n",
    "#### {'svc__gamma': 0.1, 'svc__kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch for random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 28.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 100,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test_forrest_grid = {}\n",
    "score_train_forrest_grid = {}\n",
    "for nrows in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = nrows,stratify=y)\n",
    "    forrest = RandomForestClassifier( \n",
    "                                    n_estimators = 1400,\n",
    "                                    min_samples_split = 2,\n",
    "                                    max_features= 'auto',\n",
    "                                    max_depth = 100,\n",
    "                                    bootstrap = True,\n",
    "                                    random_state= 1,\n",
    "                                    )\n",
    "    #pca = PCA(n_components=22)\n",
    "    #sc.fit(X_train)\n",
    "    #X_train = sc.transform(X_train)\n",
    "    #X_test = sc.transform(X_test)\n",
    "    #X_train = pca.fit_transform(X_train)\n",
    "    #X_test = pca.transform(X_test)\n",
    "    forrest.fit(X_train, y_train)\n",
    "    accuracy_test = forrest.score(X_test, y_test)\n",
    "    accuracy_train = forrest.score(X_train, y_train)\n",
    "    score_test_forrest_grid[nrows] = accuracy_test\n",
    "    score_train_forrest_grid[nrows] = accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.7264416315049227,\n",
       " 1: 0.7243319268635724,\n",
       " 2: 0.7250351617440225,\n",
       " 3: 0.710267229254571,\n",
       " 4: 0.7306610407876231}"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_test_forrest_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0}"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_train_forrest_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.710239651416122,\n",
       " 0.7138707334785767,\n",
       " 0.7342047930283224,\n",
       " 0.7421931735657226,\n",
       " 0.7189542483660131]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_forrest_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron algoritme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas = [0.001, 0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterasjoner_eta = [(x, y) for x in range(10,500, 50) for y in etas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultater = pd.DataFrame(index = range(5), columns = iterasjoner_eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "score_pca = []\n",
    "for nrows in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state = nrows,stratify=y)\n",
    "    for iterasjoner, eta in iterasjoner_eta:\n",
    "        pca = PCA(n_components=22)\n",
    "        sc.fit(X_train)\n",
    "        X_train = sc.transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "        ppn = Perceptron(max_iter=iterasjoner, eta0= eta, random_state = 1)\n",
    "        ppn.fit(X_train, y_train)\n",
    "        y_pred = ppn.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        score_pca.append(accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "for nrows in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state = nrows, stratify=y)\n",
    "    for iterasjoner, eta in iterasjoner_eta:\n",
    "        #random = df_train.sample(n = nrows).values\n",
    "        sc.fit(X_train)\n",
    "        \n",
    "        X_train_std = sc.transform(X_train)\n",
    "        X_test_std = sc.transform(X_test)\n",
    "        ppn = Perceptron(max_iter=iterasjoner, eta0= eta, random_state = 1)\n",
    "        ppn.fit(X_train_std, y_train)\n",
    "        y_pred = ppn.predict(X_test_std)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        score.append(accuracy)\n",
    "        resultater.loc[nrows, (iterasjoner,eta)] = accuracy\n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48148148148148145"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4575714955461791"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(score_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(10, 0.001)</th>\n",
       "      <th>(10, 0.1)</th>\n",
       "      <th>(10, 1)</th>\n",
       "      <th>(10, 10)</th>\n",
       "      <th>(10, 100)</th>\n",
       "      <th>(60, 0.001)</th>\n",
       "      <th>(60, 0.1)</th>\n",
       "      <th>(60, 1)</th>\n",
       "      <th>(60, 10)</th>\n",
       "      <th>(60, 100)</th>\n",
       "      <th>...</th>\n",
       "      <th>(410, 0.001)</th>\n",
       "      <th>(410, 0.1)</th>\n",
       "      <th>(410, 1)</th>\n",
       "      <th>(410, 10)</th>\n",
       "      <th>(410, 100)</th>\n",
       "      <th>(460, 0.001)</th>\n",
       "      <th>(460, 0.1)</th>\n",
       "      <th>(460, 1)</th>\n",
       "      <th>(460, 10)</th>\n",
       "      <th>(460, 100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.579934</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.579934</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579934</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.579934</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.616034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.576653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585091</td>\n",
       "      <td>0.629161</td>\n",
       "      <td>0.629161</td>\n",
       "      <td>0.629161</td>\n",
       "      <td>0.629161</td>\n",
       "      <td>0.585091</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585091</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>0.585091</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>0.570089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "      <td>0.577121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.587436</td>\n",
       "      <td>0.64557</td>\n",
       "      <td>0.64557</td>\n",
       "      <td>0.64557</td>\n",
       "      <td>0.64557</td>\n",
       "      <td>0.587436</td>\n",
       "      <td>0.62541</td>\n",
       "      <td>0.62541</td>\n",
       "      <td>0.62541</td>\n",
       "      <td>0.62541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587436</td>\n",
       "      <td>0.62541</td>\n",
       "      <td>0.62541</td>\n",
       "      <td>0.62541</td>\n",
       "      <td>0.62541</td>\n",
       "      <td>0.587436</td>\n",
       "      <td>0.62541</td>\n",
       "      <td>0.62541</td>\n",
       "      <td>0.62541</td>\n",
       "      <td>0.62541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  (10, 0.001) (10, 0.1)   (10, 1)  (10, 10) (10, 100) (60, 0.001) (60, 0.1)  \\\n",
       "0    0.579934  0.616034  0.616034  0.616034  0.616034    0.579934  0.616034   \n",
       "1    0.576653  0.576653  0.576653  0.576653  0.576653    0.576653  0.576653   \n",
       "2    0.585091  0.629161  0.629161  0.629161  0.629161    0.585091  0.570089   \n",
       "3    0.577121  0.577121  0.577121  0.577121  0.577121    0.577121  0.577121   \n",
       "4    0.587436   0.64557   0.64557   0.64557   0.64557    0.587436   0.62541   \n",
       "\n",
       "    (60, 1)  (60, 10) (60, 100)  ... (410, 0.001) (410, 0.1)  (410, 1)  \\\n",
       "0  0.616034  0.616034  0.616034  ...     0.579934   0.616034  0.616034   \n",
       "1  0.576653  0.576653  0.576653  ...     0.576653   0.576653  0.576653   \n",
       "2  0.570089  0.570089  0.570089  ...     0.585091   0.570089  0.570089   \n",
       "3  0.577121  0.577121  0.577121  ...     0.577121   0.577121  0.577121   \n",
       "4   0.62541   0.62541   0.62541  ...     0.587436    0.62541   0.62541   \n",
       "\n",
       "  (410, 10) (410, 100) (460, 0.001) (460, 0.1)  (460, 1) (460, 10) (460, 100)  \n",
       "0  0.616034   0.616034     0.579934   0.616034  0.616034  0.616034   0.616034  \n",
       "1  0.576653   0.576653     0.576653   0.576653  0.576653  0.576653   0.576653  \n",
       "2  0.570089   0.570089     0.585091   0.570089  0.570089  0.570089   0.570089  \n",
       "3  0.577121   0.577121     0.577121   0.577121  0.577121  0.577121   0.577121  \n",
       "4   0.62541    0.62541     0.587436    0.62541   0.62541   0.62541    0.62541  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultater#.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Perceptron the highest accuracy value was: 0.6455696202531646 \n",
      "The epoch was: (10, 0.1) \n"
     ]
    }
   ],
   "source": [
    "highest_value_ppn = max(list(resultater.max())) #storing the highest value found in the dataset\n",
    "epoch_iteration_ppn = resultater.max().idxmax() #storing the epoch that was assosciated with highest value\n",
    "print(f'For Perceptron the highest accuracy value was: {highest_value_ppn} \\nThe epoch was: {epoch_iteration_ppn} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [0.001,0.01,0.1,1,10,100,1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultater_lr = pd.DataFrame(index = range(5), columns = d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "score_pca_lr = []\n",
    "for nrows in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state = nrows,stratify=y)\n",
    "    for tune in d:\n",
    "        pca = PCA(n_components=19)\n",
    "        sc.fit(X_train)\n",
    "        X_train = sc.transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "        lr = LogisticRegression(C = tune, random_state = 1)\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        score_pca_lr.append(accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "score_test_lr = []\n",
    "score_train_lr = []\n",
    "for nrows in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = nrows,stratify=y)\n",
    "    for tune in d:\n",
    "        lr = LogisticRegression(C = tune, random_state = 1,solver ='liblinear', penalty = 'l2')\n",
    "        sc.fit(X_train)\n",
    "        X_train_std = sc.transform(X_train)\n",
    "        X_test_std = sc.transform(X_test)\n",
    "        lr.fit(X_train_std, y_train)\n",
    "        #y_pred_test = lr.predict(X_test_std)\n",
    "        #y_pred_train = lr.predict(X_train_std)\n",
    "        \n",
    "        accuracy_test = lr.score(X_test_std, y_test)\n",
    "        accuracy_train = lr.score(X_train_std, y_train)\n",
    "        score_test_lr.append(accuracy_test)\n",
    "        score_train_lr.append(accuracy_train)\n",
    "        resultater_lr.loc[nrows, tune] = accuracy_test\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5126582278481012"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(score_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.520928596552937"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(score_train_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5171120487576184"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(score_pca_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.010</th>\n",
       "      <th>0.100</th>\n",
       "      <th>1.000</th>\n",
       "      <th>10.000</th>\n",
       "      <th>100.000</th>\n",
       "      <th>1000.000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.66948</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.665963</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>0.664557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.675105</td>\n",
       "      <td>0.670886</td>\n",
       "      <td>0.673699</td>\n",
       "      <td>0.673699</td>\n",
       "      <td>0.673699</td>\n",
       "      <td>0.673699</td>\n",
       "      <td>0.673699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.668073</td>\n",
       "      <td>0.665963</td>\n",
       "      <td>0.661041</td>\n",
       "      <td>0.661744</td>\n",
       "      <td>0.661041</td>\n",
       "      <td>0.661041</td>\n",
       "      <td>0.661041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.680028</td>\n",
       "      <td>0.680731</td>\n",
       "      <td>0.679325</td>\n",
       "      <td>0.677215</td>\n",
       "      <td>0.676512</td>\n",
       "      <td>0.676512</td>\n",
       "      <td>0.675809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.680028</td>\n",
       "      <td>0.68917</td>\n",
       "      <td>0.690577</td>\n",
       "      <td>0.689873</td>\n",
       "      <td>0.68917</td>\n",
       "      <td>0.68917</td>\n",
       "      <td>0.68917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.001     0.010     0.100     1.000     10.000    100.000   1000.000\n",
       "0   0.66948  0.666667  0.665963  0.664557  0.664557  0.664557  0.664557\n",
       "1  0.675105  0.670886  0.673699  0.673699  0.673699  0.673699  0.673699\n",
       "2  0.668073  0.665963  0.661041  0.661744  0.661041  0.661041  0.661041\n",
       "3  0.680028  0.680731  0.679325  0.677215  0.676512  0.676512  0.675809\n",
       "4  0.680028   0.68917  0.690577  0.689873   0.68917   0.68917   0.68917"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultater_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Logistic regression the highest accuracy value was: 0.6905766526019691 \n",
      "The c value was: 0.1\n"
     ]
    }
   ],
   "source": [
    "highest_value_lr = max(list(resultater_lr.max())) #storing the highest value found in the dataset\n",
    "epoch_iteration_lr = resultater_lr.max().idxmax() #storing the epoch that was assosciated with highest value\n",
    "print(f'For Logistic regression the highest accuracy value was: {highest_value_lr} \\nThe c value was: {epoch_iteration_lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector classifier (SVC kernel=’linear’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultater_svm = pd.DataFrame(index = range(5), columns = c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-233-0d4e732105d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score_pca_svm = []\n",
    "for nrows in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state = nrows,stratify=y)\n",
    "    for tune in c:\n",
    "        pca = PCA(n_components=19)\n",
    "        sc.fit(X_train)\n",
    "        X_train = sc.transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "        svm = SVC(kernel = 'linear', C = tune, random_state = 1)\n",
    "        svm.fit(X_train, y_train)\n",
    "        y_pred = svm.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        score_pca_svm.append(accuracy)\n",
    "        #resultater_svm.loc[nrows, tune] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-daaa04f98215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscore_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtune\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "score_svm = []\n",
    "for nrows in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state = nrows,stratify=y)\n",
    "    for tune in c:\n",
    "        svm = SVC(kernel = 'linear', C = tune, random_state = 1)\n",
    "        sc.fit(X_train)\n",
    "        X_train_std = sc.transform(X_train)\n",
    "        X_test_std = sc.transform(X_test)\n",
    "        svm.fit(X_train_std, y_train)\n",
    "        y_pred = svm.predict(X_test_std)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        score_svm.append(accuracy)\n",
    "        resultater_svm.loc[nrows, tune] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pca_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score_svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-51f2e80441e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_svm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'score_svm' is not defined"
     ]
    }
   ],
   "source": [
    "max(score_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_value_svm = max(list(resultater_svm.max())) #storing the highest value found in the dataset\n",
    "epoch_iteration_svm = resultater_svm.max().idxmax() #storing the epoch that was assosciated with highest value\n",
    "index_value_svm = resultater_svm[(epoch_iteration_svm)].max() #Getting the index for that value as well\n",
    "print(f'For svc linear the highest accuracy value was: {highest_value_svm} \\nThe c value was: {epoch_iteration_svm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector classifier (SVC kernel=’rbf’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "gam = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_c = [(gamma, c) for gamma in gam for c in [0.1, 1, 10, 100, 1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultater_svm_rbf = pd.DataFrame(index = range(5), columns = gamma_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_columns = ['f1', 'f2', 'f3', 'f4', 'f5', 'f7','f9', 'f10','f12','f14', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_pandas = df_train.loc[:, rb_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rbf = rbf_pandas.values\n",
    "y_rbf = rbf_pandas.values\n",
    "X_rbf = X_rbf[:, :10]\n",
    "y_rbf = np.where(y_rbf[:,-1] == 0,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-4032300fa91e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX_train_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mX_test_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msvm_r\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_r\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score_svm_r = []\n",
    "for nrows in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = nrows,stratify=y)\n",
    "    for gam, tune in gamma_c:\n",
    "        svm_r = SVC(kernel = 'rbf', C = tune, gamma = gam, random_state = 1)\n",
    "        sc.fit(X_train)\n",
    "        X_train_std = sc.transform(X_train)\n",
    "        X_test_std = sc.transform(X_test)\n",
    "        svm_r.fit(X_train_std, y_train)\n",
    "        y_pred = svm_r.predict(X_test_std)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        score_svm_r.append(accuracy)\n",
    "        resultater_svm_rbf.loc[nrows, (gam,tune)] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60056258790436"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(score_svm_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0.0001, 0.1)</th>\n",
       "      <th>(0.0001, 1)</th>\n",
       "      <th>(0.0001, 10)</th>\n",
       "      <th>(0.0001, 100)</th>\n",
       "      <th>(0.0001, 1000)</th>\n",
       "      <th>(0.001, 0.1)</th>\n",
       "      <th>(0.001, 1)</th>\n",
       "      <th>(0.001, 10)</th>\n",
       "      <th>(0.001, 100)</th>\n",
       "      <th>(0.001, 1000)</th>\n",
       "      <th>...</th>\n",
       "      <th>(100, 0.1)</th>\n",
       "      <th>(100, 1)</th>\n",
       "      <th>(100, 10)</th>\n",
       "      <th>(100, 100)</th>\n",
       "      <th>(100, 1000)</th>\n",
       "      <th>(1000, 0.1)</th>\n",
       "      <th>(1000, 1)</th>\n",
       "      <th>(1000, 10)</th>\n",
       "      <th>(1000, 100)</th>\n",
       "      <th>(1000, 1000)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.394515</td>\n",
       "      <td>0.490858</td>\n",
       "      <td>0.505626</td>\n",
       "      <td>0.521097</td>\n",
       "      <td>0.394515</td>\n",
       "      <td>0.494374</td>\n",
       "      <td>0.519691</td>\n",
       "      <td>0.535865</td>\n",
       "      <td>0.554852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.401547</td>\n",
       "      <td>0.491561</td>\n",
       "      <td>0.510549</td>\n",
       "      <td>0.516174</td>\n",
       "      <td>0.40225</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.517581</td>\n",
       "      <td>0.542194</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.389592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.389592</td>\n",
       "      <td>0.395921</td>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.513361</td>\n",
       "      <td>0.519691</td>\n",
       "      <td>0.396624</td>\n",
       "      <td>0.485232</td>\n",
       "      <td>0.522504</td>\n",
       "      <td>0.529536</td>\n",
       "      <td>0.552743</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  (0.0001, 0.1) (0.0001, 1) (0.0001, 10) (0.0001, 100) (0.0001, 1000)  \\\n",
       "0      0.389592    0.394515     0.490858      0.505626       0.521097   \n",
       "1      0.389592    0.401547     0.491561      0.510549       0.516174   \n",
       "2      0.389592    0.395921     0.481013      0.513361       0.519691   \n",
       "3           NaN         NaN          NaN           NaN            NaN   \n",
       "4           NaN         NaN          NaN           NaN            NaN   \n",
       "\n",
       "  (0.001, 0.1) (0.001, 1) (0.001, 10) (0.001, 100) (0.001, 1000)  ...  \\\n",
       "0     0.394515   0.494374    0.519691     0.535865      0.554852  ...   \n",
       "1      0.40225   0.493671    0.517581     0.542194      0.556962  ...   \n",
       "2     0.396624   0.485232    0.522504     0.529536      0.552743  ...   \n",
       "3          NaN        NaN         NaN          NaN           NaN  ...   \n",
       "4          NaN        NaN         NaN          NaN           NaN  ...   \n",
       "\n",
       "  (100, 0.1)  (100, 1) (100, 10) (100, 100) (100, 1000) (1000, 0.1) (1000, 1)  \\\n",
       "0   0.389592  0.389592  0.389592   0.389592    0.389592    0.389592  0.389592   \n",
       "1   0.389592  0.389592  0.389592   0.389592    0.389592    0.389592  0.389592   \n",
       "2        NaN       NaN       NaN        NaN         NaN         NaN       NaN   \n",
       "3        NaN       NaN       NaN        NaN         NaN         NaN       NaN   \n",
       "4        NaN       NaN       NaN        NaN         NaN         NaN       NaN   \n",
       "\n",
       "  (1000, 10) (1000, 100) (1000, 1000)  \n",
       "0   0.389592    0.389592     0.389592  \n",
       "1   0.389592    0.389592     0.389592  \n",
       "2        NaN         NaN          NaN  \n",
       "3        NaN         NaN          NaN  \n",
       "4        NaN         NaN          NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultater_svm_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For support vector classifier rbf the highest accuracy value was: 0.720112517580872 \n",
      "The gamma_c value was: (0.01, 100)\n"
     ]
    }
   ],
   "source": [
    "highest_value_svm_rbf = max(list(resultater_svm_rbf.max())) #storing the highest value found in the dataset\n",
    "epoch_iteration_svm_rbf = resultater_svm_rbf.max().idxmax() #storing the epoch that was assosciated with highest value\n",
    "print(f'For support vector classifier rbf the highest accuracy value was: {highest_value_svm_rbf} \\nThe gamma_c value was: {epoch_iteration_svm_rbf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultater_trees = pd.DataFrame(index = range(5), columns = range(1,21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_trees_pca = []\n",
    "for nrows in range(1,5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = nrows,stratify=y)\n",
    "    for depth in range(1,21):\n",
    "        tree = DecisionTreeClassifier(criterion='gini', \n",
    "                                      max_depth = depth,\n",
    "                                      random_state= 1)\n",
    "        \n",
    "        pca = PCA(n_components=19)\n",
    "        sc.fit(X_train)\n",
    "        X_train = sc.transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "        \n",
    "        tree.fit(X_train, y_train)\n",
    "        accuracy = tree.score(X_test, y_test)\n",
    "        score_trees_pca.append(accuracy)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_trees = []\n",
    "for nrows in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = nrows,stratify=y)\n",
    "    for depth in range(1,21):\n",
    "        tree = DecisionTreeClassifier(criterion='gini', \n",
    "                                      max_depth = depth,\n",
    "                                      random_state= 1)\n",
    "        sc.fit(X_train)\n",
    "        X_train = sc.transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        \n",
    "        tree.fit(X_train, y_train)\n",
    "        accuracy = tree.score(X_test, y_test)\n",
    "        score_trees.append(accuracy)\n",
    "        resultater_trees.loc[nrows, depth] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5822784810126582"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(score_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.490154711673699"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(score_trees_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435302</td>\n",
       "      <td>0.459212</td>\n",
       "      <td>0.441632</td>\n",
       "      <td>0.514065</td>\n",
       "      <td>0.524613</td>\n",
       "      <td>0.537975</td>\n",
       "      <td>0.519691</td>\n",
       "      <td>0.541491</td>\n",
       "      <td>0.527426</td>\n",
       "      <td>0.547117</td>\n",
       "      <td>0.558368</td>\n",
       "      <td>0.561885</td>\n",
       "      <td>0.560478</td>\n",
       "      <td>0.543601</td>\n",
       "      <td>0.537975</td>\n",
       "      <td>0.537975</td>\n",
       "      <td>0.531646</td>\n",
       "      <td>0.539381</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.536568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.424051</td>\n",
       "      <td>0.457103</td>\n",
       "      <td>0.456399</td>\n",
       "      <td>0.514065</td>\n",
       "      <td>0.507032</td>\n",
       "      <td>0.526723</td>\n",
       "      <td>0.537271</td>\n",
       "      <td>0.540788</td>\n",
       "      <td>0.540084</td>\n",
       "      <td>0.550633</td>\n",
       "      <td>0.54571</td>\n",
       "      <td>0.540084</td>\n",
       "      <td>0.536568</td>\n",
       "      <td>0.542194</td>\n",
       "      <td>0.529536</td>\n",
       "      <td>0.540788</td>\n",
       "      <td>0.538678</td>\n",
       "      <td>0.540084</td>\n",
       "      <td>0.528833</td>\n",
       "      <td>0.533052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.441632</td>\n",
       "      <td>0.457806</td>\n",
       "      <td>0.446554</td>\n",
       "      <td>0.500703</td>\n",
       "      <td>0.505626</td>\n",
       "      <td>0.535162</td>\n",
       "      <td>0.523207</td>\n",
       "      <td>0.538678</td>\n",
       "      <td>0.54571</td>\n",
       "      <td>0.551336</td>\n",
       "      <td>0.557665</td>\n",
       "      <td>0.54993</td>\n",
       "      <td>0.550633</td>\n",
       "      <td>0.566104</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.561885</td>\n",
       "      <td>0.549226</td>\n",
       "      <td>0.553446</td>\n",
       "      <td>0.548523</td>\n",
       "      <td>0.553446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.436006</td>\n",
       "      <td>0.453586</td>\n",
       "      <td>0.45218</td>\n",
       "      <td>0.499297</td>\n",
       "      <td>0.495077</td>\n",
       "      <td>0.534459</td>\n",
       "      <td>0.550633</td>\n",
       "      <td>0.537975</td>\n",
       "      <td>0.549226</td>\n",
       "      <td>0.542194</td>\n",
       "      <td>0.554149</td>\n",
       "      <td>0.563994</td>\n",
       "      <td>0.552039</td>\n",
       "      <td>0.557665</td>\n",
       "      <td>0.557665</td>\n",
       "      <td>0.528833</td>\n",
       "      <td>0.540084</td>\n",
       "      <td>0.540084</td>\n",
       "      <td>0.515471</td>\n",
       "      <td>0.526723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.432489</td>\n",
       "      <td>0.457103</td>\n",
       "      <td>0.469058</td>\n",
       "      <td>0.495077</td>\n",
       "      <td>0.541491</td>\n",
       "      <td>0.535865</td>\n",
       "      <td>0.548523</td>\n",
       "      <td>0.560478</td>\n",
       "      <td>0.57384</td>\n",
       "      <td>0.566807</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.564698</td>\n",
       "      <td>0.567511</td>\n",
       "      <td>0.562588</td>\n",
       "      <td>0.57384</td>\n",
       "      <td>0.558368</td>\n",
       "      <td>0.574543</td>\n",
       "      <td>0.554149</td>\n",
       "      <td>0.560478</td>\n",
       "      <td>0.556259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.435302  0.459212  0.441632  0.514065  0.524613  0.537975  0.519691   \n",
       "1  0.424051  0.457103  0.456399  0.514065  0.507032  0.526723  0.537271   \n",
       "2  0.441632  0.457806  0.446554  0.500703  0.505626  0.535162  0.523207   \n",
       "3  0.436006  0.453586   0.45218  0.499297  0.495077  0.534459  0.550633   \n",
       "4  0.432489  0.457103  0.469058  0.495077  0.541491  0.535865  0.548523   \n",
       "\n",
       "          8         9        10        11        12        13        14  \\\n",
       "0  0.541491  0.527426  0.547117  0.558368  0.561885  0.560478  0.543601   \n",
       "1  0.540788  0.540084  0.550633   0.54571  0.540084  0.536568  0.542194   \n",
       "2  0.538678   0.54571  0.551336  0.557665   0.54993  0.550633  0.566104   \n",
       "3  0.537975  0.549226  0.542194  0.554149  0.563994  0.552039  0.557665   \n",
       "4  0.560478   0.57384  0.566807  0.582278  0.564698  0.567511  0.562588   \n",
       "\n",
       "         15        16        17        18        19        20  \n",
       "0  0.537975  0.537975  0.531646  0.539381  0.544304  0.536568  \n",
       "1  0.529536  0.540788  0.538678  0.540084  0.528833  0.533052  \n",
       "2  0.555556  0.561885  0.549226  0.553446  0.548523  0.553446  \n",
       "3  0.557665  0.528833  0.540084  0.540084  0.515471  0.526723  \n",
       "4   0.57384  0.558368  0.574543  0.554149  0.560478  0.556259  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultater_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6962025316455697"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(score_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For DecisionTrees the highest accuracy value was: 0.6962025316455697 \n",
      "The max_depth value was: 6\n"
     ]
    }
   ],
   "source": [
    "highest_value_trees = max(list(resultater_trees.max())) #storing the highest value found in the dataset\n",
    "epoch_iteration_trees = resultater_trees.max().idxmax() #storing the epoch that was assosciated with highest value\n",
    "print(f'For DecisionTrees the highest accuracy value was: {highest_value_trees} \\nThe max_depth value was: {epoch_iteration_trees}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = [1, 10, 100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultater_forrest = pd.DataFrame(index = range(5), columns = [kk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_forrest_pca = []\n",
    "for nrows in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = nrows,stratify=y)\n",
    "    for k in kk:\n",
    "        forrest = RandomForestClassifier(criterion='gini', \n",
    "                                      n_estimators = k,\n",
    "                                      random_state= 1)\n",
    "        pca = PCA(n_components=19)\n",
    "        sc.fit(X_train)\n",
    "        X_train = sc.transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "        forrest.fit(X_train, y_train)\n",
    "        accuracy = forrest.score(X_test, y_test)\n",
    "        score_forrest_pca.append(accuracy)\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_forrest = []\n",
    "for nrows in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = nrows,stratify=y)\n",
    "    for k in kk:\n",
    "        forrest = RandomForestClassifier(criterion='gini', \n",
    "                                      n_estimators = k,\n",
    "                                      random_state= 1)\n",
    "        \n",
    "        forrest.fit(X_train, y_train)\n",
    "        accuracy = forrest.score(X_test, y_test)\n",
    "        score_forrest.append(accuracy)\n",
    "        resultater_forrest.loc[nrows, k] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7051561365286856"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(score_forrest_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7358490566037735"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(score_forrest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6122</td>\n",
       "      <td>0.669572</td>\n",
       "      <td>0.706609</td>\n",
       "      <td>0.713145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.559187</td>\n",
       "      <td>0.67756</td>\n",
       "      <td>0.724038</td>\n",
       "      <td>0.716776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6122</td>\n",
       "      <td>0.687001</td>\n",
       "      <td>0.721859</td>\n",
       "      <td>0.730574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.619463</td>\n",
       "      <td>0.709513</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.744372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.625272</td>\n",
       "      <td>0.688453</td>\n",
       "      <td>0.716776</td>\n",
       "      <td>0.71968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1         10        100       200\n",
       "0    0.6122  0.669572  0.706609  0.713145\n",
       "1  0.559187   0.67756  0.724038  0.716776\n",
       "2    0.6122  0.687001  0.721859  0.730574\n",
       "3  0.619463  0.709513  0.745098  0.744372\n",
       "4  0.625272  0.688453  0.716776   0.71968"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultater_forrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_keep = ['f1', 'f2', 'f3', 'f13', 'f15', 'f17', 'f18', 'f19', 'f20', 'f21', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pandas = df_train.loc[:, columns_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_knn = knn_pandas.values\n",
    "y_knn = knn_pandas.values\n",
    "X_knn = X_knn[:, :10]\n",
    "y_knn = np.where(y_knn[:, -1] == 0,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['euclidean', 'manhattan', 'chebyshev', 'minkowski']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "puttinnforfaen = [(naboer, metric) for naboer in range(1,20) for metric in metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_knn_pca = {}\n",
    "for nrows in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state = nrows,stratify=y)\n",
    "    for naboer, metrics in puttinnforfaen:\n",
    "        knn = KNeighborsClassifier(n_neighbors=naboer, \n",
    "                                      p = 2,\n",
    "                                      metric = metrics)\n",
    "        pca = PCA(n_components=19)\n",
    "        sc.fit(X_train)\n",
    "        X_train = sc.transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "        \n",
    "        knn.fit(X_train, y_train)\n",
    "        accuracy = knn.score(X_test, y_test)\n",
    "        score_knn_pca[(naboer, metrics)] = accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_knn = {}\n",
    "for nrows in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state = nrows,stratify=y)\n",
    "    for naboer, metrics in puttinnforfaen:\n",
    "        knn = KNeighborsClassifier(n_neighbors=naboer, \n",
    "                                      p = 2,\n",
    "                                      metric = metrics)\n",
    "        #sc.fit(X_train)\n",
    "        #X_train = sc.transform(X_train)\n",
    "        #X_test = sc.transform(X_test)\n",
    "        knn.fit(X_train, y_train)\n",
    "        accuracy = knn.score(X_test, y_test)\n",
    "        score_knn[(naboer, metrics)] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 'euclidean'): 0.44960150023441164,\n",
       " (1, 'manhattan'): 0.48476324425691514,\n",
       " (1, 'chebyshev'): 0.4270979840600094,\n",
       " (1, 'minkowski'): 0.44960150023441164,\n",
       " (2, 'euclidean'): 0.43741209563994377,\n",
       " (2, 'manhattan'): 0.4608532583216127,\n",
       " (2, 'chebyshev'): 0.42756680731364277,\n",
       " (2, 'minkowski'): 0.43741209563994377,\n",
       " (3, 'euclidean'): 0.4571026722925457,\n",
       " (3, 'manhattan'): 0.4880450070323488,\n",
       " (3, 'chebyshev'): 0.43975621190811065,\n",
       " (3, 'minkowski'): 0.4571026722925457,\n",
       " (4, 'euclidean'): 0.44678856071261136,\n",
       " (4, 'manhattan'): 0.47257383966244726,\n",
       " (4, 'chebyshev'): 0.4388185654008439,\n",
       " (4, 'minkowski'): 0.44678856071261136,\n",
       " (5, 'euclidean'): 0.45241443975621193,\n",
       " (5, 'manhattan'): 0.4739803094233474,\n",
       " (5, 'chebyshev'): 0.44678856071261136,\n",
       " (5, 'minkowski'): 0.45241443975621193,\n",
       " (6, 'euclidean'): 0.44585091420534456,\n",
       " (6, 'manhattan'): 0.4608532583216127,\n",
       " (6, 'chebyshev'): 0.44678856071261136,\n",
       " (6, 'minkowski'): 0.44585091420534456,\n",
       " (7, 'euclidean'): 0.4453820909517112,\n",
       " (7, 'manhattan'): 0.4542897327707454,\n",
       " (7, 'chebyshev'): 0.44256915142991093,\n",
       " (7, 'minkowski'): 0.4453820909517112,\n",
       " (8, 'euclidean'): 0.45944678856071264,\n",
       " (8, 'manhattan'): 0.4669479606188467,\n",
       " (8, 'chebyshev'): 0.44256915142991093,\n",
       " (8, 'minkowski'): 0.45944678856071264,\n",
       " (9, 'euclidean'): 0.4575714955461791,\n",
       " (9, 'manhattan'): 0.45288326300984527,\n",
       " (9, 'chebyshev'): 0.43319268635724334,\n",
       " (9, 'minkowski'): 0.4575714955461791,\n",
       " (10, 'euclidean'): 0.45288326300984527,\n",
       " (10, 'manhattan'): 0.4617909048288795,\n",
       " (10, 'chebyshev'): 0.4345991561181435,\n",
       " (10, 'minkowski'): 0.45288326300984527,\n",
       " (11, 'euclidean'): 0.45194561650257853,\n",
       " (11, 'manhattan'): 0.45616502578527895,\n",
       " (11, 'chebyshev'): 0.42944210032817626,\n",
       " (11, 'minkowski'): 0.45194561650257853,\n",
       " (12, 'euclidean'): 0.4603844350679794,\n",
       " (12, 'manhattan'): 0.46554149085794655,\n",
       " (12, 'chebyshev'): 0.4345991561181435,\n",
       " (12, 'minkowski'): 0.4603844350679794,\n",
       " (13, 'euclidean'): 0.45663384903891235,\n",
       " (13, 'manhattan'): 0.46319737458977966,\n",
       " (13, 'chebyshev'): 0.4341303328645101,\n",
       " (13, 'minkowski'): 0.45663384903891235,\n",
       " (14, 'euclidean'): 0.45335208626347867,\n",
       " (14, 'manhattan'): 0.46882325363338023,\n",
       " (14, 'chebyshev'): 0.4435067979371777,\n",
       " (14, 'minkowski'): 0.45335208626347867,\n",
       " (15, 'euclidean'): 0.45850914205344584,\n",
       " (15, 'manhattan'): 0.45850914205344584,\n",
       " (15, 'chebyshev'): 0.4439756211908111,\n",
       " (15, 'minkowski'): 0.45850914205344584,\n",
       " (16, 'euclidean'): 0.4552273792780122,\n",
       " (16, 'manhattan'): 0.4692920768870136,\n",
       " (16, 'chebyshev'): 0.43694327238631037,\n",
       " (16, 'minkowski'): 0.4552273792780122,\n",
       " (17, 'euclidean'): 0.45288326300984527,\n",
       " (17, 'manhattan'): 0.4613220815752461,\n",
       " (17, 'chebyshev'): 0.44163150492264414,\n",
       " (17, 'minkowski'): 0.45288326300984527,\n",
       " (18, 'euclidean'): 0.4481950304735115,\n",
       " (18, 'manhattan'): 0.4617909048288795,\n",
       " (18, 'chebyshev'): 0.44585091420534456,\n",
       " (18, 'minkowski'): 0.4481950304735115,\n",
       " (19, 'euclidean'): 0.4575714955461791,\n",
       " (19, 'manhattan'): 0.4608532583216127,\n",
       " (19, 'chebyshev'): 0.4477262072198781,\n",
       " (19, 'minkowski'): 0.4575714955461791}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 'manhattan') : 0.6692493946731235\n",
      "(13, 'chebyshev') : 0.6474576271186441\n",
      "(14, 'manhattan') : 0.6658595641646489\n",
      "(19, 'manhattan') : 0.6774818401937046\n",
      "(5, 'euclidean') : 0.6547215496368038\n",
      "(5, 'minkowski') : 0.6547215496368038\n",
      "(11, 'manhattan') : 0.6644067796610169\n",
      "(17, 'chebyshev') : 0.6547215496368038\n"
     ]
    }
   ],
   "source": [
    "from heapq import nlargest \n",
    "\n",
    "storste = nlargest(8, score_knn_pca, key = score_knn_pca.get)\n",
    "\n",
    "for val in storste: \n",
    "    print(val, \":\", score_knn.get(val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 'manhattan') : 0.6774818401937046\n",
      "(17, 'manhattan') : 0.6731234866828087\n",
      "(13, 'manhattan') : 0.6721549636803874\n",
      "(15, 'manhattan') : 0.6716707021791768\n",
      "(18, 'manhattan') : 0.6716707021791768\n",
      "(5, 'manhattan') : 0.6692493946731235\n",
      "(16, 'manhattan') : 0.6673123486682808\n",
      "(14, 'manhattan') : 0.6658595641646489\n"
     ]
    }
   ],
   "source": [
    "from heapq import nlargest \n",
    "\n",
    "storste = nlargest(8, score_knn, key = score_knn.get)\n",
    "\n",
    "for val in storste: \n",
    "    print(val, \":\", score_knn.get(val)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7069479210278613"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sequential backward selection(sbs)\n",
    "sbs = SFS(RandomForestClassifier( \n",
    "                                    n_estimators = 800,\n",
    "                                    min_samples_split = 2,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    max_features= 'sqrt',\n",
    "                                    max_depth = 136,\n",
    "                                    bootstrap = False,\n",
    "                                    random_state= 1,\n",
    "                                    ), \n",
    "          k_features=(10,24), \n",
    "          forward=False, \n",
    "          floating=False,\n",
    "          cv=5,\n",
    "          n_jobs = -1\n",
    "          )\n",
    "sbs.fit(X, y)\n",
    "sbs.k_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0', '2', '3', '14', '17', '18', '19', '21', '22', '23')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbs.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-313db255f2b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_feature_names_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "X.columns[sbs.k_feature_names_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['f1', 'f3', 'f4', 'f15', 'f18', 'f19', 'f20', 'f22', 'f23', 'f24', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_pandas = df_train.loc[:, column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = sb_pandas.drop('label',1).values\n",
    "ys = sb_pandas['label'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7108, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test_forrest_grid = {}\n",
    "score_train_forrest_grid = {}\n",
    "for nrows in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xs, ys, test_size= 0.2, random_state = nrows,stratify=ys)\n",
    "    forrest = RandomForestClassifier( \n",
    "                                    n_estimators = 800,\n",
    "                                    min_samples_split = 2,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    max_features= 'sqrt',\n",
    "                                    max_depth = 136,\n",
    "                                    bootstrap = False,\n",
    "                                    random_state= 1,\n",
    "                                    )\n",
    "    #pca = PCA(n_components=22)\n",
    "    #sc.fit(X_train)\n",
    "    #X_train = sc.transform(X_train)\n",
    "    #X_test = sc.transform(X_test)\n",
    "    #X_train = pca.fit_transform(X_train)\n",
    "    #X_test = pca.transform(X_test)\n",
    "    forrest.fit(X_train, y_train)\n",
    "    pred = forrest.predict(X_test)\n",
    "    accuracy_test = forrest.score(X_test, y_test)\n",
    "    accuracy_train = forrest.score(X_train, y_train)\n",
    "    score_test_forrest_grid[nrows] = accuracy_test\n",
    "    score_train_forrest_grid[nrows] = accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6849507735583685,\n",
       " 1: 0.7039381153305204,\n",
       " 2: 0.6954992967651196,\n",
       " 3: 0.7046413502109705,\n",
       " 4: 0.7208157524613221}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_test_forrest_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest = RandomForestClassifier( \n",
    "                                    n_estimators = 800,\n",
    "                                    min_samples_split = 2,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    max_features= 'sqrt',\n",
    "                                    max_depth = 136,\n",
    "                                    bootstrap = False,\n",
    "                                    random_state= 1,\n",
    "                                    )\n",
    "forrest.fit(Xs,ys)\n",
    "predict = forrest.predict(df_test.loc[:, column[:-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: innlevering.csv\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv(\"../data/test.csv\")\n",
    "predictions = forrest.predict(X_test[column[:-1]])\n",
    "submission = pd.DataFrame({'ID':X_test.index,'label':predictions})\n",
    "submission.astype(int).to_csv('innlevering.csv', index=False)\n",
    "print('Saved file: ' + 'innlevering.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.astype(int).to_csv('this.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score på 72%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CA3 - Work for a secret customer.pdf',\n",
       " '.DS_Store',\n",
       " 'test.csv',\n",
       " 'train-kopi.xml',\n",
       " 'train.csv',\n",
       " 'filename',\n",
       " 'filename.csv',\n",
       " 'sample_submission.csv']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fabiannemazi/Fag_nmbu/Dat200/CA3/Data\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
